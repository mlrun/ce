global:

  # External host/ip to reach the k8s node. This might take various values if k8s is run in a VM or a cloud env
  externalHostAddress: localhost
  registry:
    url: mustprovide
    secretName: secretNameofcontainerregistrymustprovide

mlrun:
  # set the type of filesystem to use: filesystem, s3
  storage: filesystem
  api:
    fullnameOverride: mlrun-api
    persistence:
      enabled: true
      annotations:
        helm.sh/resource-policy: "keep"
    extraEnv:
      - name: MLRUN_SPARK_OPERATOR_VERSION
        value: spark-3
      - name: MLRUN_STORAGE__AUTO_MOUNT_TYPE
        value: s3
      - name: MLRUN_STORAGE__AUTO_MOUNT_PARAMS
        value: "aws_access_key=minio,aws_secret_key=minio123,endpoint_url=http://minio.mlrun.svc.cluster.local:9000"
      - name: MLRUN_HTTPDB__PROJECTS__FOLLOWERS
        value: nuclio
      - name: S3_ENDPOINT_URL
        value: http://minio.mlrun.svc.cluster.local:9000
      - name: AWS_SECRET_ACCESS_KEY
        value: minio123
      - name: AWS_ACCESS_KEY_ID
        value: minio
      - name: MLRUN_HTTPDB__REAL_PATH
        value: s3://
      - name: MLRUN_ARTIFACT_PATH
        value: s3://mlrun/
      - name: MLRUN_SPARK_APP_IMAGE
        value: gcr.io/iguazio/spark-app
      - name: MLRUN_SPARK_APP_IMAGE_TAG
        value: v3.2.1-mlk
      - name: MLRUN_KFP_URL
        value: http://ml-pipeline.mlrun.svc.cluster.local:8888
  db:
    persistence:
      enabled: true
      annotations:
        helm.sh/resource-policy: "keep"

jupyterNotebook:
  persistence:
    enabled: true
    annotations:
      helm.sh/resource-policy: "keep"

minio:
  enabled: true
  rootUser: minio
  rootPassword: minio123
  mode: distributed
  replicas: 4
  resources:
    requests:
      memory: 0.5Gi
  persistence:
    enabled: true
    size: 1Gi

spark-operator:
  enabled: true
  fullnameOverride: spark-operator
  webhook:
     enable: true

pipelines:
  enabled: true
  name: pipelines
  persistence:
    enabled: true
    existingClaim:
    storageClass:
    accessMode: "ReadWriteOnce"
    size: "20Gi"
    annotations:
      helm.sh/resource-policy: "keep"
  db:
    username: root
  minio:
    enabled: true
    accessKey: "minio"
    secretKey: "minio123"
    endpoint: "minio.mlrun.svc.cluster.local"
    endpointPort: "9000"
    bucket: "mlrun"
  images:
    argoexec:
      repository: gcr.io/ml-pipeline/argoexec
      tag: v3.3.8-license-compliance
    workflowController:
      repository: gcr.io/ml-pipeline/workflow-controller
      tag: v3.3.8-license-compliance
    apiServer:
      repository: gcr.io/ml-pipeline/api-server
      tag: 1.8.3
    persistenceagent:
      repository: gcr.io/ml-pipeline/persistenceagent
      tag: 1.8.3
    scheduledworkflow:
      repository: gcr.io/ml-pipeline/scheduledworkflow
      tag: 1.8.3
    ui:
      repository: gcr.io/ml-pipeline/frontend
      tag: 1.8.3
    viewerCrdController:
      repository: gcr.io/ml-pipeline/viewer-crd-controller
      tag: 1.8.3
    visualizationServer:
      repository: gcr.io/ml-pipeline/visualization-server
      tag: 1.8.3
    metadata:
      container:
        repository: gcr.io/tfx-oss-public/ml_metadata_store_server
        tag: 1.5.0
    metadataEnvoy:
      repository: gcr.io/ml-pipeline/metadata-envoy
      tag: 1.8.3
    metadataWriter:
      repository: gcr.io/ml-pipeline/metadata-writer
      tag: 1.8.3
    mysql:
      repository: mysql
      tag: 5.7-debian
    cacheImage:
      repository: gcr.io/google-containers/busybox
      tag: latest

kube-prometheus-stack:
  fullnameOverride: monitoring
  enabled: true
  alertmanager:
    enabled: false
  grafana:
    adminUser: "admin"
    adminPassword: "admin-passw123"
    fullnameOverride: grafana
    enabled: true
    service:
      type: NodePort
      nodePort: 30110
  prometheus:
    enabled: true
  kube-state-metrics:
    fullnameOverride: state-metrics
  prometheus-node-exporter:
    fullnameOverride: node-exporter
